{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"#working correctly\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport cv2\nimport shutil\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPooling2D\nfrom tensorflow.keras.callbacks import TensorBoard\nimport random","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"TRAIN_DIR = '../input/flowers-recognition/flowers/'\nTEST_DIR = 'test_data/'\n#os.mkdir('test_data')\nIMG_SIZE = 100\nLR = 1e-3\nos.listdir()","execution_count":62,"outputs":[{"output_type":"execute_result","execution_count":62,"data":{"text/plain":"['__notebook_source__.ipynb', '.ipynb_checkpoints', 'test_data']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#25 random files from each sample have been placed into TEST_DIR\npath = os.listdir(TRAIN_DIR)\n#print(path)\nfor x in path:\n    #appending name to the path\n    if x != 'flowers':\n        path_2 = os.path.join(TRAIN_DIR,x)\n        #print(path_2)\n        file_data = os.listdir(path_2)\n        #print(file_data)\n        #taking 25 pics from each sample and placing in test folder\n        for num in range(25):\n            index = random.randrange(0, len(file_data))\n            #print(file_data[index])\n            path_source = os.path.join(path_2,file_data[index])\n            #print(path_source)\n            move_file = shutil.copy(path_source, TEST_DIR)","execution_count":33,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"#working now\ndef label_image(path_source):\n    word_label = path_source.split('/')[4]\n    if word_label == 'tulip': return 0\n    elif word_label == 'sunflower': return 1\n    elif word_label == 'rose': return 2\n    elif word_label == 'daisy': return 3\n    elif word_label == 'dandelion': return 4","execution_count":161,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#create train data\ndef create_train_data():\n    train_data = []\n    path = os.listdir(TRAIN_DIR)\n    #print(path)\n    for x in tqdm(path):\n        #appending name to the path\n        if x != 'flowers':\n            path_2 = os.path.join(TRAIN_DIR,x)\n            #print(path_2)\n            file_data = os.listdir(path_2)\n            for num in file_data:\n                index = random.randrange(0, len(file_data))\n                if file_data[index] != 'flickr.pyc' and file_data[index] != 'flickr.py' and file_data[index] != 'run_me.py':\n                    path_source = os.path.join(path_2,file_data[index])\n                    #print(path_source)\n                    #print(label_image(path_source))\n                    try:\n                        label = label_image(path_source)\n                        img = cv2.resize(cv2.imread(path_source, cv2.IMREAD_GRAYSCALE),(IMG_SIZE, IMG_SIZE))\n                        train_data.append([np.array(img),np.array(label)])\n                \n                    except Exception as e:\n                        print(path_source)\n                        print(str(e))\n                        \n    np.save('traindata.npy',train_data)\n    print(\"Training data created successfully\")\n    return train_data\n            \n        \n","execution_count":162,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#working fine now\ntrain_data = create_train_data()","execution_count":163,"outputs":[{"output_type":"stream","text":"100%|██████████| 6/6 [00:09<00:00,  1.62s/it]","name":"stderr"},{"output_type":"stream","text":"Training data created successfully\n","name":"stdout"},{"output_type":"stream","text":"\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#working fine now\ndef process_test_data():\n    test_data = []\n    #path = os.listdir(TEST_DIR)\n    #print(path)\n    for x in tqdm(os.listdir(TEST_DIR)):\n        path_2 = os.path.join(TEST_DIR,x)\n        #print(x)\n        try:\n            img_id = x.split('.')[0]\n            #print(img_id)\n            img = cv2.resize(cv2.imread(path_2, cv2.IMREAD_GRAYSCALE),(IMG_SIZE, IMG_SIZE))\n            test_data.append([np.array(img),np.array(img_id)])\n        \n        except Exception as e:\n            print(path_source)\n            print(str(e))\n    np.save('testdata.npy',train_data)\n    print(\"Testing data created successfully\")\n    return test_data","execution_count":179,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = process_test_data()","execution_count":180,"outputs":[{"output_type":"stream","text":"100%|██████████| 123/123 [00:00<00:00, 752.80it/s]\n","name":"stderr"},{"output_type":"stream","text":"Testing data created successfully\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model = Sequential()\nmy_model.add(Conv2D(32,(2,2),activation='relu', input_shape = (IMG_SIZE,IMG_SIZE,1)))\nmy_model.add(Conv2D(64,(2,2),activation='relu'))\nmy_model.add(MaxPooling2D(pool_size=(2,2)))\nmy_model.add(Conv2D(32,(2,2),activation='relu', input_shape = (IMG_SIZE,IMG_SIZE,1)))\nmy_model.add(Conv2D(64,(2,2),activation='relu'))\nmy_model.add(MaxPooling2D(pool_size=(2,2)))\nmy_model.add(Flatten())\nmy_model.add(Dense(128,activation='relu'))\nmy_model.add(Flatten())\nmy_model.add(Dense(5,activation='softmax'))","execution_count":157,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X = ([i[0] for i in train_data])\nX = np.array(X)\nX = X.reshape(X.shape[0], IMG_SIZE, IMG_SIZE, 1)\n\nY = ([i[1] for i in train_data])\nY = np.array(Y)","execution_count":164,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model.compile(loss = 'sparse_categorical_crossentropy',optimizer = 'adam', metrics = ['accuracy'])","execution_count":165,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"my_model.fit(X,Y, epochs = 5, validation_split = 0.15)","execution_count":166,"outputs":[{"output_type":"stream","text":"Train on 3672 samples, validate on 649 samples\nEpoch 1/5\n3672/3672 [==============================] - 66s 18ms/sample - loss: 8.1602 - accuracy: 0.3619 - val_loss: 2.3102 - val_accuracy: 0.1125\nEpoch 2/5\n3672/3672 [==============================] - 65s 18ms/sample - loss: 0.9303 - accuracy: 0.6697 - val_loss: 2.0736 - val_accuracy: 0.2943\nEpoch 3/5\n3672/3672 [==============================] - 65s 18ms/sample - loss: 0.4766 - accuracy: 0.8429 - val_loss: 2.1896 - val_accuracy: 0.4438\nEpoch 4/5\n3672/3672 [==============================] - 66s 18ms/sample - loss: 0.2322 - accuracy: 0.9319 - val_loss: 1.7521 - val_accuracy: 0.6163\nEpoch 5/5\n3672/3672 [==============================] - 67s 18ms/sample - loss: 0.1045 - accuracy: 0.9725 - val_loss: 1.7350 - val_accuracy: 0.5917\n","name":"stdout"},{"output_type":"execute_result","execution_count":166,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fd3106f5790>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt","execution_count":167,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = process_test_data()","execution_count":181,"outputs":[{"output_type":"stream","text":"100%|██████████| 123/123 [00:00<00:00, 757.05it/s]\n","name":"stderr"},{"output_type":"stream","text":"Testing data created successfully\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"fig = plt.figure()\nfor num, data in enumerate(test_data[:30]):\n    img_num = data[1]\n    img_data_test = data[0]\n    y = fig.add_subplot(5,6,num+1)\n    #y = fig.tight_layout(pad=0.5)\n    orig = data[0]\n    #data = np.array(data)\n    data = orig.reshape(1,IMG_SIZE, IMG_SIZE,1)\n    model_out = my_model.predict([data])[0]\n    #print(model_out)\n    if np.argmax(model_out) == 0: str_label = 'Tulip'\n    elif np.argmax(model_out) == 1: str_label = 'Sunflower' \n    elif np.argmax(model_out) == 2: str_label = 'Rose'\n    elif np.argmax(model_out) == 3: str_label = 'Daisy'\n    elif np.argmax(model_out) == 4: str_label = 'Dandelion'\n    #else: str_label = 'Dog'\n    y.imshow(orig,cmap = 'gray')\n    plt.title(str_label)\n    y.axes.get_xaxis().set_visible(False)\n    y.axes.get_yaxis().set_visible(False)\n    y = fig.tight_layout(pad=0.5)\n    \nplt.show()","execution_count":198,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"cannot reshape array of size 10000 into shape (1,200,200,1)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-198-a463e0d6dce9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#data = np.array(data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMG_SIZE\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mmodel_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmy_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#print(model_out)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 10000 into shape (1,200,200,1)"]},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAE4AAABICAYAAABY88MAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAACQklEQVR4nO3cMWsUURiF4fcYSZPaKgoqSMKWrmhnHStbUwup/AH+EZsUwU6xtLO1sTAphIgI0cZgIWKvBD4LEYIG9u5hZjOTnAe22DAZvrzMMrkwd1VVxPwunPYAY5VwpoQzJZwp4UwJZ5oZTtKOpG+S9hcx0Fi0XHFPgY2e5xidmeGq6jXwYwGzjMrFrk4kaQvYAlhZWZmur693deqF2tvb+15Vl2YeWFUzX8BVYL/l2KpiOp3WWAG71fA35q5qSjhTy78jz4A3wJqkQ0kP+x9r+GbeHKpqcxGDjE0+qqaEMyWcKeFMCWdKOFPCmRLOlHCmhDMlnCnhTAlnSjhTwpkSzpRwpoQzJZwp4UwJZ0o4U8KZEs6UcKaEMyWcKeFMCWdqCidpQ9JHSQeSHvc91Bi0PB+3BDwB7gETYFPSpO/Bhq7lirsNHFTV56r6BTwH7vc71vC1PHW+Cnw59v4QuPPvQcefOgd+jnhDyVrLQS3hdMLP/tsdXFXbwDaApN2qutUywNBI2m05ruWjeghcOfb+MvDVGeosaQn3Frgh6ZqkZeAB8LLfsYav5eHpI0mPgFfAErBTVe9n/Np2F8OdkqbZVfkyA0tWDqaEM3UabsxLs7k3NLfslGt58efG8Qm4DiwD74BJV+fv+wXcBW7SuEuyyytu1EuzmnNDc5fhTlqarXZ4/kHpMlzT0uys6DLcuVqadRnuXC3NOgtXVUfA36XZB+BFw9JsMObd0JwllykrB1PCmRLOlHCmhDMlnCnhTL8B5eZTTt+cCYMAAAAASUVORK5CYII=\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}